# Fuchsia - RL Training Framework

A flexible and efficient framework for Group Relative Policy Optimization (GRPO) training with support for LoRA fine-tuning, distributed training, and various model configurations.

## Features

- **GRPO Training**: Implementation of Group Relative Policy Optimization algorithm
- **LoRA Support**: Efficient fine-tuning with Low-Rank Adaptation
- **Distributed Training**: Support for multi-GPU setups
- **Single node Training**: Works on single gpu with hotswap mode
- **Gradient Checkpointing**: Memory-efficient training options with cpu offloading

## Installation
